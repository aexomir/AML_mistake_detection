{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# AML - Step 2 & Step 3 Runner (Colab)\n",
        "\n",
        "This notebook runs Step 2 (feature sanity check) and Step 3 (evaluation) using `scripts/run.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone repository (or upload your code)\n",
        "!git clone --recursive https://github.com/sapeirone/aml-2025-mistake-detection.git code || echo \"Repo already exists or using uploaded code\"\n",
        "\n",
        "# Change to code directory\n",
        "import os\n",
        "os.chdir('code')\n",
        "print(f\"Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torcheval\n",
        "!pip install -q -r requirements-cpu.txt 2>/dev/null || pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mount_drive"
      },
      "source": [
        "## 2. Mount Google Drive (Optional)\n",
        "\n",
        "If your features and checkpoints are in Google Drive, mount it here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "## 3. Load Data & Checkpoints\n",
        "\n",
        "Uncomment and update paths to your features and checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_features"
      },
      "outputs": [],
      "source": [
        "# Option 1: From Google Drive\n",
        "# !mkdir -p data\n",
        "# !unzip \"/content/drive/MyDrive/path/to/features.zip\" -d data/\n",
        "\n",
        "# Option 2: From URL (if available)\n",
        "# !wget -q <features_url> -O features.zip && unzip -q features.zip -d data/\n",
        "\n",
        "# Option 3: Already in repo/data directory\n",
        "print(\"Features should be in: data/video/omnivore/ and data/video/slowfast/\")\n",
        "!ls -la data/ 2>/dev/null || echo \"Data directory not found - please add your features\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_checkpoints"
      },
      "outputs": [],
      "source": [
        "# Option 1: From Google Drive\n",
        "# !mkdir -p checkpoints\n",
        "# !unzip \"/content/drive/MyDrive/path/to/error_recognition_best.zip\" -d checkpoints/\n",
        "\n",
        "# Option 2: From URL\n",
        "# Download from: https://utdallas.app.box.com/s/uz3s1alrzucz03sleify8kazhuc1ksl3\n",
        "# !wget -q <checkpoint_url> -O checkpoints.zip && unzip -q checkpoints.zip -d checkpoints/\n",
        "\n",
        "# Option 3: Already in repo\n",
        "print(\"Checkpoints should be in: checkpoints/error_recognition_best/\")\n",
        "!ls -la checkpoints/ 2>/dev/null || echo \"Checkpoints directory not found - please add your checkpoints\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## 4. Step 2: Feature Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step2"
      },
      "outputs": [],
      "source": [
        "# Run Step 2 with default path (data/)\n",
        "!python scripts/run.py step2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step2_custom"
      },
      "outputs": [],
      "source": [
        "# Or specify custom features root\n",
        "# !python scripts/run.py step2 --features_root /path/to/features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## 5. Step 3: Evaluation Reproduction\n",
        "\n",
        "Run evaluations for different backbones, variants, and splits. Update checkpoint paths with actual epoch numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_mlp_step"
      },
      "outputs": [],
      "source": [
        "# Omnivore - MLP - Step split\n",
        "!python scripts/run.py step3 --split step --backbone omnivore --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_mlp_recordings"
      },
      "outputs": [],
      "source": [
        "# Omnivore - MLP - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone omnivore --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_transformer_step"
      },
      "outputs": [],
      "source": [
        "# Omnivore - Transformer - Step split\n",
        "!python scripts/run.py step3 --split step --backbone omnivore --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_transformer_recordings"
      },
      "outputs": [],
      "source": [
        "# Omnivore - Transformer - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone omnivore --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_mlp_step"
      },
      "outputs": [],
      "source": [
        "# SlowFast - MLP - Step split\n",
        "!python scripts/run.py step3 --split step --backbone slowfast --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_mlp_recordings"
      },
      "outputs": [],
      "source": [
        "# SlowFast - MLP - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone slowfast --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_transformer_step"
      },
      "outputs": [],
      "source": [
        "# SlowFast - Transformer - Step split\n",
        "!python scripts/run.py step3 --split step --backbone slowfast --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_transformer_recordings"
      },
      "outputs": [],
      "source": [
        "# SlowFast - Transformer - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone slowfast --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
