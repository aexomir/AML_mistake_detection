{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# AML - Step 2 & Step 3 Runner (Colab)\n",
        "\n",
        "This notebook runs Step 2 (feature sanity check) and Step 3 (evaluation) using `scripts/run.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone repository (or upload your code)\n",
        "!git clone --recursive https://github.com/sapeirone/aml-2025-mistake-detection.git code || echo \"Repo already exists or using uploaded code\"\n",
        "\n",
        "# Change to code directory\n",
        "import os\n",
        "os.chdir('code')\n",
        "print(f\"Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torcheval\n",
        "!pip install -q -r requirements-cpu.txt 2>/dev/null || pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mount_drive"
      },
      "source": [
        "## 2. Mount Google Drive (Optional)\n",
        "\n",
        "If your features and checkpoints are in Google Drive, mount it here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "## 3. Load Data & Checkpoints\n",
        "\n",
        "Specify paths to your unzipped directories on Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_paths"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# UPDATE THESE PATHS TO YOUR DRIVE LOCATIONS\n",
        "# ============================================\n",
        "\n",
        "# Path to unzipped omnivore features directory on Drive\n",
        "# Should contain .npz files directly or in a subdirectory\n",
        "OMNIVORE_DRIVE_PATH = \"/content/drive/MyDrive/path/to/omnivore\"  # UPDATE THIS\n",
        "\n",
        "# Path to unzipped slowfast features directory on Drive\n",
        "# Should contain .npz files directly or in a subdirectory\n",
        "SLOWFAST_DRIVE_PATH = \"/content/drive/MyDrive/path/to/slowfast\"  # UPDATE THIS\n",
        "\n",
        "# Path to error_recognition_best checkpoints on Drive\n",
        "# Can be either:\n",
        "#   - A zip file (e.g., \"/content/drive/MyDrive/path/to/error_recognition_best.zip\")\n",
        "#   - An unzipped directory (e.g., \"/content/drive/MyDrive/path/to/error_recognition_best\")\n",
        "# Should contain MLP/ and Transformer/ subdirectories\n",
        "CHECKPOINTS_DRIVE_PATH = \"/content/drive/MyDrive/path/to/error_recognition_best.zip\"  # UPDATE THIS (can be .zip or directory)\n",
        "\n",
        "print(\"Paths configured:\")\n",
        "print(f\"  Omnivore: {OMNIVORE_DRIVE_PATH}\")\n",
        "print(f\"  SlowFast: {SLOWFAST_DRIVE_PATH}\")\n",
        "print(f\"  Checkpoints: {CHECKPOINTS_DRIVE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_features"
      },
      "outputs": [],
      "source": [
        "# Create data directory structure\n",
        "!mkdir -p data/video/omnivore\n",
        "!mkdir -p data/video/slowfast\n",
        "\n",
        "# Copy omnivore features from Drive\n",
        "print(\"Copying Omnivore features...\")\n",
        "!cp -r \"{OMNIVORE_DRIVE_PATH}\"/* data/video/omnivore/ 2>/dev/null || \\\n",
        "  (echo \"Warning: Could not copy from {OMNIVORE_DRIVE_PATH}\" && \\\n",
        "   echo \"Trying alternative: copying contents if path points to parent directory...\" && \\\n",
        "   find \"{OMNIVORE_DRIVE_PATH}\" -name \"*.npz\" -exec cp {} data/video/omnivore/ \\; 2>/dev/null || true)\n",
        "\n",
        "# Copy slowfast features from Drive\n",
        "print(\"Copying SlowFast features...\")\n",
        "!cp -r \"{SLOWFAST_DRIVE_PATH}\"/* data/video/slowfast/ 2>/dev/null || \\\n",
        "  (echo \"Warning: Could not copy from {SLOWFAST_DRIVE_PATH}\" && \\\n",
        "   echo \"Trying alternative: copying contents if path points to parent directory...\" && \\\n",
        "   find \"{SLOWFAST_DRIVE_PATH}\" -name \"*.npz\" -exec cp {} data/video/slowfast/ \\; 2>/dev/null || true)\n",
        "\n",
        "# Verify features were copied\n",
        "print(\"\\nVerifying features...\")\n",
        "print(f\"Omnivore files: $(ls -1 data/video/omnivore/*.npz 2>/dev/null | wc -l) .npz files\")\n",
        "print(f\"SlowFast files: $(ls -1 data/video/slowfast/*.npz 2>/dev/null | wc -l) .npz files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_checkpoints"
      },
      "outputs": [],
      "source": [
        "# Create checkpoints directory\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "\n",
        "checkpoint_path = CHECKPOINTS_DRIVE_PATH\n",
        "\n",
        "# Check if path is a zip file or directory\n",
        "is_zip = checkpoint_path.lower().endswith('.zip')\n",
        "if not is_zip:\n",
        "    is_zip = os.path.isfile(checkpoint_path) if os.path.exists(checkpoint_path) else False\n",
        "\n",
        "if is_zip:\n",
        "    print(f\"Detected zip file: {checkpoint_path}\")\n",
        "    print(\"Copying zip file to temporary location...\")\n",
        "    shutil.copy(checkpoint_path, '/tmp/checkpoints.zip')\n",
        "    \n",
        "    print(\"Unzipping checkpoints...\")\n",
        "    subprocess.run(['unzip', '-q', '/tmp/checkpoints.zip', '-d', '/tmp/checkpoints_extracted'], check=True)\n",
        "    \n",
        "    # Find the error_recognition_best directory in the extracted files\n",
        "    extracted_base = '/tmp/checkpoints_extracted'\n",
        "    extracted_path = None\n",
        "    \n",
        "    # Check if error_recognition_best is at the root\n",
        "    if os.path.exists(os.path.join(extracted_base, 'error_recognition_best')):\n",
        "        extracted_path = os.path.join(extracted_base, 'error_recognition_best')\n",
        "    else:\n",
        "        # Check if MLP/Transformer are directly in extracted_base\n",
        "        if os.path.exists(os.path.join(extracted_base, 'MLP')) or os.path.exists(os.path.join(extracted_base, 'Transformer')):\n",
        "            extracted_path = extracted_base\n",
        "        else:\n",
        "            # Search for error_recognition_best in subdirectories\n",
        "            for root, dirs, files in os.walk(extracted_base):\n",
        "                if 'error_recognition_best' in dirs:\n",
        "                    extracted_path = os.path.join(root, 'error_recognition_best')\n",
        "                    break\n",
        "                # Or check if MLP/Transformer are here\n",
        "                if 'MLP' in dirs or 'Transformer' in dirs:\n",
        "                    extracted_path = root\n",
        "                    break\n",
        "            \n",
        "            if extracted_path is None:\n",
        "                extracted_path = extracted_base\n",
        "    \n",
        "    print(f\"Copying from extracted location: {extracted_path}\")\n",
        "    shutil.copytree(extracted_path, 'checkpoints/error_recognition_best', dirs_exist_ok=True)\n",
        "    \n",
        "    # Cleanup\n",
        "    shutil.rmtree('/tmp/checkpoints_extracted', ignore_errors=True)\n",
        "    os.remove('/tmp/checkpoints.zip')\n",
        "    print(\"✓ Checkpoints extracted and copied\")\n",
        "else:\n",
        "    print(f\"Detected directory: {checkpoint_path}\")\n",
        "    print(\"Copying checkpoints from directory...\")\n",
        "    if os.path.basename(checkpoint_path) == 'error_recognition_best':\n",
        "        shutil.copytree(checkpoint_path, 'checkpoints/error_recognition_best', dirs_exist_ok=True)\n",
        "    else:\n",
        "        os.makedirs('checkpoints/error_recognition_best', exist_ok=True)\n",
        "        for item in os.listdir(checkpoint_path):\n",
        "            src = os.path.join(checkpoint_path, item)\n",
        "            dst = os.path.join('checkpoints/error_recognition_best', item)\n",
        "            if os.path.isdir(src):\n",
        "                shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "            else:\n",
        "                shutil.copy2(src, dst)\n",
        "    print(\"✓ Checkpoints copied\")\n",
        "\n",
        "# Verify checkpoints were loaded\n",
        "print(\"\\nVerifying checkpoints...\")\n",
        "if os.path.exists('checkpoints/error_recognition_best'):\n",
        "    print(\"✓ Checkpoints directory exists\")\n",
        "    # Count .pt files\n",
        "    pt_files = []\n",
        "    for root, dirs, files in os.walk('checkpoints/error_recognition_best'):\n",
        "        pt_files.extend([os.path.join(root, f) for f in files if f.endswith('.pt')])\n",
        "    print(f\"Found {len(pt_files)} checkpoint files (.pt)\")\n",
        "    if pt_files:\n",
        "        print(\"\\nSample checkpoint files:\")\n",
        "        for f in pt_files[:5]:\n",
        "            print(f\"  {f}\")\n",
        "    \n",
        "    # Show directory structure\n",
        "    print(\"\\nDirectory structure:\")\n",
        "    for root, dirs, files in os.walk('checkpoints/error_recognition_best'):\n",
        "        level = root.replace('checkpoints/error_recognition_best', '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        if level < 3:  # Limit depth for readability\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for d in dirs[:5]:  # Show first 5 dirs\n",
        "                print(f\"{subindent}{d}/\")\n",
        "else:\n",
        "    print(\"✗ Checkpoints directory not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## 4. Step 2: Feature Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step2"
      },
      "outputs": [],
      "source": [
        "# Run Step 2 with default path (data/)\n",
        "!python scripts/run.py step2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step2_custom"
      },
      "outputs": [],
      "source": [
        "# Or specify custom features root\n",
        "# !python scripts/run.py step2 --features_root /path/to/features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## 5. Step 3: Evaluation Reproduction\n",
        "\n",
        "Run evaluations for different backbones, variants, and splits. Update checkpoint paths with actual epoch numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_mlp_step"
      },
      "outputs": [],
      "source": [
        "# Omnivore - MLP - Step split\n",
        "!python scripts/run.py step3 --split step --backbone omnivore --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_mlp_recordings"
      },
      "outputs": [],
      "source": [
        "# Omnivore - MLP - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone omnivore --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_transformer_step"
      },
      "outputs": [],
      "source": [
        "# Omnivore - Transformer - Step split\n",
        "!python scripts/run.py step3 --split step --backbone omnivore --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_omnivore_transformer_recordings"
      },
      "outputs": [],
      "source": [
        "# Omnivore - Transformer - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone omnivore --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_mlp_step"
      },
      "outputs": [],
      "source": [
        "# SlowFast - MLP - Step split\n",
        "!python scripts/run.py step3 --split step --backbone slowfast --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_mlp_recordings"
      },
      "outputs": [],
      "source": [
        "# SlowFast - MLP - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone slowfast --variant MLP \\\n",
        "  --ckpt checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_transformer_step"
      },
      "outputs": [],
      "source": [
        "# SlowFast - Transformer - Step split\n",
        "!python scripts/run.py step3 --split step --backbone slowfast --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_step_epoch_XX.pt \\\n",
        "  --threshold 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_step3_slowfast_transformer_recordings"
      },
      "outputs": [],
      "source": [
        "# SlowFast - Transformer - Recordings split\n",
        "!python scripts/run.py step3 --split recordings --backbone slowfast --variant Transformer \\\n",
        "  --ckpt checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_recordings_epoch_XX.pt \\\n",
        "  --threshold 0.4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
