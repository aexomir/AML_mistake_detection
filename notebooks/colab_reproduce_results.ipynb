{"cells":[{"cell_type":"markdown","metadata":{"id":"IbXK2y_qUdbb"},"source":["# AML/DAAI 2025 - Mistake Detection: Reproduce Results on Colab\n","\n","This notebook helps you reproduce the results from the paper using `scripts/run.py`.\n","\n","## What this notebook does:\n","1. **Step 2**: Feature sanity check - verifies your features are loaded correctly\n","2. **Step 3**: Evaluation reproduction - runs the evaluation to reproduce paper results\n","\n","## Prerequisites:\n","You need to have:\n","- Pre-extracted features (Omnivore and SlowFast) in `.npz` format\n","- Checkpoints from the official release (`error_recognition_best` directory)\n","- Annotation files (should be in the repository or uploaded separately)\n","\n","## Quick Start:\n","1. Upload your data to Google Drive (or use direct upload)\n","2. Configure paths in Section 1\n","3. Run all cells sequentially\n"]},{"cell_type":"markdown","metadata":{"id":"uBNnxXN2Udbc"},"source":["## 1. Setup: Clone Repository & Install Dependencies\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"snQdZoi4Udbc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808199678,"user_tz":-60,"elapsed":6,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"3585c6e6-21f7-43a0-b682-bc4cd612cdac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Repository URL: https://github.com/aexomir/AML_mistake_detection.git\n","Repository branch: feat/step02\n","Repository directory: aml_repo_v2\n"]}],"source":["# ============================================\n","# CONFIGURE YOUR REPOSITORY\n","# ============================================\n","# Option 1: Clone from GitHub (recommended)\n","REPO_URL = \"https://github.com/aexomir/AML_mistake_detection.git\"\n","REPO_BRANCH = \"feat/step02\"  # Leave empty for default branch, or specify branch name\n","\n","# Option 2: Manual upload - set REPO_URL to empty string and upload files manually\n","# REPO_URL = \"\"\n","\n","REPO_DIR = \"aml_repo_v2\"\n","\n","print(f\"Repository URL: {REPO_URL if REPO_URL else 'Manual upload mode'}\")\n","print(f\"Repository branch: {REPO_BRANCH if REPO_BRANCH else 'default'}\")\n","print(f\"Repository directory: {REPO_DIR}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_GU4eR39Udbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808203015,"user_tz":-60,"elapsed":1435,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"e6a48888-8f47-4124-eb17-23dbabefe3e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning repository from https://github.com/aexomir/AML_mistake_detection.git...\n","✓ Repository cloned successfully\n","Checking out branch: feat/step02\n","✓ Switched to branch: feat/step02\n","\n","✓ Changed to directory: /content/aml_repo/aml_repo_v2\n","\n","Repository contents:\n","total 6020\n","drwxr-xr-x  8 root root    4096 Dec 15 14:16 .\n","drwxr-xr-x 12 root root    4096 Dec 15 14:16 ..\n","-rw-r--r--  1 root root 6042142 Dec 15 14:16 3_Mistake_Detection.pdf\n","-rw-r--r--  1 root root   18838 Dec 15 14:16 base.py\n","-rw-r--r--  1 root root    1661 Dec 15 14:16 constants.py\n","drwxr-xr-x  3 root root    4096 Dec 15 14:16 core\n","drwxr-xr-x  2 root root    4096 Dec 15 14:16 dataloader\n","-rw-r--r--  1 root root    6148 Dec 15 14:16 .DS_Store\n","drwxr-xr-x  2 root root    4096 Dec 15 14:16 er_annotations\n","drwxr-xr-x  8 root root    4096 Dec 15 14:16 .git\n","-rw-r--r--  1 root root      65 Dec 15 14:16 .gitignore\n","-rwxr-xr-x  1 root root    1904 Dec 15 14:16 install_deps.py\n","-rw-r--r--  1 root root   11357 Dec 15 14:16 LICENSE\n","drwxr-xr-x  2 root root    4096 Dec 15 14:16 notebooks\n","-rw-r--r--  1 root root    2298 Dec 15 14:16 overview.md\n","-rw-r--r--  1 root root    2496 Dec 15 14:16 README.md\n","-rw-r--r--  1 root root     124 Dec 15 14:16 requirements-cpu.txt\n","-rw-r--r--  1 root root     193 Dec 15 14:16 requirements-cuda.txt\n","-rw-r--r--  1 root root     304 Dec 15 14:16 requirements.txt\n","drwxr-xr-x  2 root root    4096 Dec 15 14:16 scripts\n","-rw-r--r--  1 root root    4596 Dec 15 14:16 step_guide.md\n","-rwxr-xr-x  1 root root    1027 Dec 15 14:16 train_er.py\n"]}],"source":["import os\n","import shutil\n","\n","# Remove existing directory if it exists\n","if os.path.exists(REPO_DIR):\n","    print(f\"Removing existing {REPO_DIR} directory...\")\n","    shutil.rmtree(REPO_DIR)\n","\n","# Clone repository\n","if REPO_URL:\n","    print(f\"Cloning repository from {REPO_URL}...\")\n","    clone_cmd = f\"git clone {REPO_URL} {REPO_DIR}\"\n","    result = os.system(clone_cmd)\n","\n","    if result != 0:\n","        print(f\"⚠ Clone failed. Please check the URL or upload files manually.\")\n","        os.makedirs(REPO_DIR, exist_ok=True)\n","    else:\n","        print(\"✓ Repository cloned successfully\")\n","\n","        # Checkout specific branch if specified\n","        if REPO_BRANCH:\n","            print(f\"Checking out branch: {REPO_BRANCH}\")\n","            os.chdir(REPO_DIR)\n","            os.system(f\"git checkout {REPO_BRANCH}\")\n","            os.chdir('..')\n","            print(f\"✓ Switched to branch: {REPO_BRANCH}\")\n","else:\n","    print(\"Manual upload mode: Creating directory...\")\n","    os.makedirs(REPO_DIR, exist_ok=True)\n","\n","# Change to repository directory\n","if os.path.exists(REPO_DIR):\n","    os.chdir(REPO_DIR)\n","    print(f\"\\n✓ Changed to directory: {os.getcwd()}\")\n","    print(f\"\\nRepository contents:\")\n","    !ls -la\n","else:\n","    print(f\"✗ Error: {REPO_DIR} directory not found!\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"AM1hHgs5Udbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808206750,"user_tz":-60,"elapsed":7,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"8631930f-eaed-4585-d809-ee0b8a7884a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content/aml_repo/aml_repo_v2\n","\n","Checking repository structure...\n","✓ Found: scripts/run.py\n","✓ Found: core/evaluate.py\n","✓ Found: dataloader\n","✓ Found: base.py\n","✓ Found: constants.py\n","\n","✓ Repository structure looks good!\n"]}],"source":["# Verify repository structure\n","import os\n","\n","print(f\"Current working directory: {os.getcwd()}\")\n","print(f\"\\nChecking repository structure...\")\n","\n","required_items = [\n","    'scripts/run.py',\n","    'core/evaluate.py',\n","    'dataloader',\n","    'base.py',\n","    'constants.py'\n","]\n","\n","missing = []\n","for item in required_items:\n","    if os.path.exists(item):\n","        print(f\"✓ Found: {item}\")\n","    else:\n","        print(f\"✗ Missing: {item}\")\n","        missing.append(item)\n","\n","if missing:\n","    print(f\"\\n⚠ Warning: Some required files/directories are missing!\")\n","    print(f\"Please ensure all files are present before proceeding.\")\n","else:\n","    print(f\"\\n✓ Repository structure looks good!\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"m8GZbD1-Udbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808218994,"user_tz":-60,"elapsed":10169,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"e6db36ff-47c8-47b5-8d5e-52eadf75e0ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ All dependencies installed successfully\n","\n","PyTorch version: 2.9.0+cu126\n","CUDA available: True\n","CUDA device: Tesla T4\n"]}],"source":["# Install dependencies\n","# Colab comes with PyTorch pre-installed, so we'll work with that\n","# Remove PyTorch version constraints to avoid conflicts\n","if os.path.exists('requirements.txt'):\n","    !sed -i '/^torch==/d' requirements.txt 2>/dev/null || true\n","    !sed -i '/^torchvision==/d' requirements.txt 2>/dev/null || true\n","\n","# Install torcheval (required for evaluation metrics)\n","!pip install -q torcheval\n","\n","# Install all remaining dependencies from requirements.txt\n","if os.path.exists('requirements.txt'):\n","    !pip install -q -r requirements.txt\n","elif os.path.exists('requirements-cpu.txt'):\n","    !pip install -q -r requirements-cpu.txt\n","\n","print(\"✓ All dependencies installed successfully\")\n","\n","# Verify PyTorch installation\n","import torch\n","print(f\"\\nPyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"nnK0NhW_Udbd"},"source":["## 2. Load Data: Features, Checkpoints, and Annotations\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"RFpEVEmrUdbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808220875,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"9bbe2ebb-6229-49a6-b40b-7c35e2ebbab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data paths configured:\n","  Use Google Drive: True\n","  Omnivore: /content/drive/MyDrive/AML_mistake_detection/omnivore.zip\n","  SlowFast: /content/drive/MyDrive/AML_mistake_detection/slowfast.zip\n","  Checkpoints: /content/drive/MyDrive/AML_mistake_detection/error_recognition_best.zip\n","  Annotations: /content/drive/MyDrive/AML_mistake_detection/annotations\n"]}],"source":["# ============================================\n","# CONFIGURE DATA PATHS\n","# ============================================\n","# Option 1: From Google Drive (recommended for large files)\n","USE_GOOGLE_DRIVE = True  # Set to False if uploading directly\n","\n","# Paths on Google Drive (update these to match your Drive structure)\n","OMNIVORE_DRIVE_PATH = \"/content/drive/MyDrive/AML_mistake_detection/omnivore.zip\"  # Can be .zip or directory\n","SLOWFAST_DRIVE_PATH = \"/content/drive/MyDrive/AML_mistake_detection/slowfast.zip\"  # Can be .zip or directory\n","CHECKPOINTS_DRIVE_PATH = \"/content/drive/MyDrive/AML_mistake_detection/error_recognition_best.zip\"  # Can be .zip or directory\n","ANNOTATIONS_DRIVE_PATH = \"/content/drive/MyDrive/AML_mistake_detection/annotations\"  # Optional if in repo\n","\n","# Option 2: Direct upload - set USE_GOOGLE_DRIVE = False and upload files in next cell\n","\n","print(\"Data paths configured:\")\n","print(f\"  Use Google Drive: {USE_GOOGLE_DRIVE}\")\n","print(f\"  Omnivore: {OMNIVORE_DRIVE_PATH}\")\n","print(f\"  SlowFast: {SLOWFAST_DRIVE_PATH}\")\n","print(f\"  Checkpoints: {CHECKPOINTS_DRIVE_PATH}\")\n","print(f\"  Annotations: {ANNOTATIONS_DRIVE_PATH}\")\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"U009SuJ-Udbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808230141,"user_tz":-60,"elapsed":2025,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"e418c417-7edc-47eb-97dd-5614a9abaeeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Google Drive mounted\n"]}],"source":["# Mount Google Drive if using it\n","if USE_GOOGLE_DRIVE:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\"✓ Google Drive mounted\")\n","else:\n","    print(\"⚠ Google Drive not mounted. Please upload files directly using the file browser.\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_5cuI84XUdbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808231757,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"94431df4-d2a5-4374-d5bb-22475779b84f"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Directory structure created\n"]}],"source":["# Create data directory structure\n","import os\n","os.makedirs('data/video/omnivore', exist_ok=True)\n","os.makedirs('data/video/slowfast', exist_ok=True)\n","os.makedirs('checkpoints', exist_ok=True)\n","os.makedirs('annotations/annotation_json', exist_ok=True)\n","os.makedirs('annotations/data_splits', exist_ok=True)\n","os.makedirs('er_annotations', exist_ok=True)\n","\n","print(\"✓ Directory structure created\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"mTscGipyUdbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808296595,"user_tz":-60,"elapsed":62298,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"a9a848c9-63f8-418e-b3ae-768a8690ebf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Omnivore features from: /content/drive/MyDrive/AML_mistake_detection/omnivore.zip\n","  Detected zip file, extracting...\n","  ✓ Extracted and copied 384 .npz files\n","Loading SlowFast features from: /content/drive/MyDrive/AML_mistake_detection/slowfast.zip\n","  Detected zip file, extracting...\n","  ✓ Extracted and copied 384 .npz files\n","\n","Feature file counts:\n","  Omnivore: 384 .npz files\n","  SlowFast: 384 .npz files\n"]}],"source":["# Load features from Google Drive or direct upload\n","import os\n","import shutil\n","import subprocess\n","import glob\n","\n","def load_features(source_path, dest_path, feature_name):\n","    \"\"\"Load features from source (zip file or directory) to destination.\"\"\"\n","    if not os.path.exists(source_path):\n","        print(f\"⚠ {feature_name}: Source path not found: {source_path}\")\n","        return False\n","\n","    print(f\"Loading {feature_name} features from: {source_path}\")\n","\n","    # Check if it's a zip file\n","    is_zip = source_path.lower().endswith('.zip') or (os.path.isfile(source_path) and 'zip' in str(source_path))\n","\n","    if is_zip:\n","        print(f\"  Detected zip file, extracting...\")\n","        temp_zip = f'/tmp/{feature_name.lower()}.zip'\n","        temp_extracted = f'/tmp/{feature_name.lower()}_extracted'\n","\n","        try:\n","            shutil.copy(source_path, temp_zip)\n","            subprocess.run(['unzip', '-q', temp_zip, '-d', temp_extracted], check=True)\n","\n","            # Find .npz files in extracted directory\n","            npz_files = glob.glob(os.path.join(temp_extracted, '**/*.npz'), recursive=True)\n","\n","            if npz_files:\n","                # Copy all .npz files to destination\n","                for npz_file in npz_files:\n","                    shutil.copy2(npz_file, dest_path)\n","                print(f\"  ✓ Extracted and copied {len(npz_files)} .npz files\")\n","\n","                # Cleanup\n","                shutil.rmtree(temp_extracted, ignore_errors=True)\n","                os.remove(temp_zip)\n","                return True\n","            else:\n","                print(f\"  ⚠ No .npz files found in extracted zip\")\n","                shutil.rmtree(temp_extracted, ignore_errors=True)\n","                os.remove(temp_zip)\n","                return False\n","        except Exception as e:\n","            print(f\"  ✗ Error extracting {feature_name} zip: {e}\")\n","            if os.path.exists(temp_extracted):\n","                shutil.rmtree(temp_extracted, ignore_errors=True)\n","            if os.path.exists(temp_zip):\n","                os.remove(temp_zip)\n","            return False\n","    else:\n","        # It's a directory\n","        print(f\"  Detected directory, copying .npz files...\")\n","        npz_files = glob.glob(os.path.join(source_path, '**/*.npz'), recursive=True)\n","\n","        if npz_files:\n","            # Copy all .npz files to destination\n","            for npz_file in npz_files:\n","                shutil.copy2(npz_file, dest_path)\n","            print(f\"  ✓ Copied {len(npz_files)} .npz files\")\n","            return True\n","        else:\n","            print(f\"  ⚠ No .npz files found in {source_path}\")\n","            return False\n","\n","# Load Omnivore and SlowFast features\n","if USE_GOOGLE_DRIVE:\n","    load_features(OMNIVORE_DRIVE_PATH, 'data/video/omnivore', 'Omnivore')\n","    load_features(SLOWFAST_DRIVE_PATH, 'data/video/slowfast', 'SlowFast')\n","else:\n","    print(\"⚠ Please upload features manually:\")\n","    print(\"  1. Use the file browser to upload .npz files or zip files\")\n","    print(\"  2. Extract/copy them to data/video/omnivore/ and data/video/slowfast/\")\n","\n","# Verify features\n","omnivore_count = len([f for f in os.listdir('data/video/omnivore') if f.endswith('.npz')]) if os.path.exists('data/video/omnivore') else 0\n","slowfast_count = len([f for f in os.listdir('data/video/slowfast') if f.endswith('.npz')]) if os.path.exists('data/video/slowfast') else 0\n","print(f\"\\nFeature file counts:\")\n","print(f\"  Omnivore: {omnivore_count} .npz files\")\n","print(f\"  SlowFast: {slowfast_count} .npz files\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"c50LOW2CUdbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808348862,"user_tz":-60,"elapsed":49091,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"3b434442-089d-4cdd-b18f-f2e1f5ad598e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading checkpoints from: /content/drive/MyDrive/AML_mistake_detection/error_recognition_best.zip\n","Detected zip file, extracting...\n","Copying from: /tmp/checkpoints_extracted/error_recognition_best\n","✓ Checkpoints extracted\n","\n","✓ Found 54 checkpoint files\n","\n","Sample checkpoint files:\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_33.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_environment_epoch_5.pt\n"]}],"source":["# Load checkpoints\n","import os\n","import shutil\n","import subprocess\n","\n","checkpoint_path = CHECKPOINTS_DRIVE_PATH if USE_GOOGLE_DRIVE else None\n","\n","if checkpoint_path and os.path.exists(checkpoint_path):\n","    print(f\"Loading checkpoints from: {checkpoint_path}\")\n","\n","    # Check if it's a zip file\n","    is_zip = checkpoint_path.lower().endswith('.zip') or (os.path.isfile(checkpoint_path) and 'zip' in str(checkpoint_path))\n","\n","    if is_zip:\n","        print(\"Detected zip file, extracting...\")\n","        shutil.copy(checkpoint_path, '/tmp/checkpoints.zip')\n","\n","        try:\n","            subprocess.run(['unzip', '-q', '/tmp/checkpoints.zip', '-d', '/tmp/checkpoints_extracted'], check=True)\n","\n","            # Find error_recognition_best directory\n","            extracted_base = '/tmp/checkpoints_extracted'\n","            extracted_path = None\n","\n","            # Check common locations\n","            if os.path.exists(os.path.join(extracted_base, 'error_recognition_best')):\n","                extracted_path = os.path.join(extracted_base, 'error_recognition_best')\n","            elif os.path.exists(os.path.join(extracted_base, 'MLP')) or os.path.exists(os.path.join(extracted_base, 'Transformer')):\n","                extracted_path = extracted_base\n","            else:\n","                # Search recursively\n","                for root, dirs, files in os.walk(extracted_base):\n","                    if 'error_recognition_best' in dirs:\n","                        extracted_path = os.path.join(root, 'error_recognition_best')\n","                        break\n","                    if 'MLP' in dirs or 'Transformer' in dirs:\n","                        extracted_path = root\n","                        break\n","\n","                if extracted_path is None:\n","                    extracted_path = extracted_base\n","\n","            print(f\"Copying from: {extracted_path}\")\n","            shutil.copytree(extracted_path, 'checkpoints/error_recognition_best', dirs_exist_ok=True)\n","\n","            # Cleanup\n","            shutil.rmtree('/tmp/checkpoints_extracted', ignore_errors=True)\n","            os.remove('/tmp/checkpoints.zip')\n","            print(\"✓ Checkpoints extracted\")\n","        except Exception as e:\n","            print(f\"✗ Error extracting checkpoints: {e}\")\n","    else:\n","        # It's a directory\n","        print(\"Detected directory, copying...\")\n","        if os.path.basename(checkpoint_path) == 'error_recognition_best':\n","            shutil.copytree(checkpoint_path, 'checkpoints/error_recognition_best', dirs_exist_ok=True)\n","        else:\n","            os.makedirs('checkpoints/error_recognition_best', exist_ok=True)\n","            for item in os.listdir(checkpoint_path):\n","                src = os.path.join(checkpoint_path, item)\n","                dst = os.path.join('checkpoints/error_recognition_best', item)\n","                if os.path.isdir(src):\n","                    shutil.copytree(src, dst, dirs_exist_ok=True)\n","                else:\n","                    shutil.copy2(src, dst)\n","        print(\"✓ Checkpoints copied\")\n","else:\n","    print(\"⚠ Checkpoints not found. Please upload manually:\")\n","    print(\"  1. Download from: https://utdallas.app.box.com/s/uz3s1alrzucz03sleify8kazhuc1ksl3\")\n","    print(\"  2. Extract error_recognition_best directory\")\n","    print(\"  3. Upload to checkpoints/error_recognition_best/\")\n","\n","# Verify checkpoints\n","if os.path.exists('checkpoints/error_recognition_best'):\n","    pt_files = []\n","    for root, dirs, files in os.walk('checkpoints/error_recognition_best'):\n","        pt_files.extend([os.path.join(root, f) for f in files if f.endswith('.pt')])\n","    print(f\"\\n✓ Found {len(pt_files)} checkpoint files\")\n","    if pt_files:\n","        print(\"\\nSample checkpoint files:\")\n","        for f in pt_files[:3]:\n","            print(f\"  {f}\")\n","else:\n","    print(\"\\n✗ Checkpoints directory not found\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MSxArZ6jUdbf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808358305,"user_tz":-60,"elapsed":7163,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"6805851a-e539-443a-ffa0-5f1ad0c0a046"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading annotations from: /content/drive/MyDrive/AML_mistake_detection/annotations\n","  ✓ Copied error_category_idx.json\n","  ✓ Copied activity_idx_step_idx.json\n","  ✓ Copied error_annotations.json\n","  ✓ Copied step_annotations.json\n","  ✓ Copied complete_step_annotations.json\n","  ✓ Copied step_idx_description.json\n","  ✓ Copied recording_id_step_idx.json\n","  ✓ Copied environment_data_split_combined.json\n","  ✓ Copied person_data_split_normal.json\n","  ✓ Copied recordings_data_split_normal.json\n","  ✓ Copied person_data_split_combined.json\n","  ✓ Copied environment_data_split_normal.json\n","  ✓ Copied recordings_data_split_combined.json\n","  ✓ Copied recipes_data_split_normal.json\n","  ✓ Copied recipes_data_split_combined.json\n","\n","Verifying annotation files...\n","✓ Found: annotations/annotation_json/step_annotations.json\n","✓ Found: annotations/annotation_json/error_annotations.json\n","✓ Found: er_annotations/recordings_combined_splits.json\n","\n","✓ All required annotation files are present!\n"]}],"source":["# Load annotations (if not already in repository)\n","import os\n","import shutil\n","\n","if USE_GOOGLE_DRIVE and os.path.exists(ANNOTATIONS_DRIVE_PATH):\n","    print(f\"Loading annotations from: {ANNOTATIONS_DRIVE_PATH}\")\n","\n","    # Copy annotation_json\n","    annotation_json_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'annotation_json')\n","    if os.path.exists(annotation_json_src):\n","        for file in os.listdir(annotation_json_src):\n","            src = os.path.join(annotation_json_src, file)\n","            dst = os.path.join('annotations/annotation_json', file)\n","            if os.path.isfile(src):\n","                shutil.copy2(src, dst)\n","                print(f\"  ✓ Copied {file}\")\n","\n","    # Copy data_splits\n","    data_splits_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'data_splits')\n","    if os.path.exists(data_splits_src):\n","        for file in os.listdir(data_splits_src):\n","            src = os.path.join(data_splits_src, file)\n","            dst = os.path.join('annotations/data_splits', file)\n","            if os.path.isfile(src):\n","                shutil.copy2(src, dst)\n","                print(f\"  ✓ Copied {file}\")\n","\n","    # Copy er_annotations\n","    er_annotations_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'er_annotations')\n","    if os.path.exists(er_annotations_src):\n","        for file in os.listdir(er_annotations_src):\n","            src = os.path.join(er_annotations_src, file)\n","            dst = os.path.join('er_annotations', file)\n","            if os.path.isfile(src):\n","                shutil.copy2(src, dst)\n","                print(f\"  ✓ Copied {file}\")\n","else:\n","    print(\"⚠ Annotations not found in Drive. Checking repository...\")\n","\n","# Verify required annotation files\n","print(\"\\nVerifying annotation files...\")\n","required_files = [\n","    'annotations/annotation_json/step_annotations.json',\n","    'annotations/annotation_json/error_annotations.json',\n","    'er_annotations/recordings_combined_splits.json'\n","]\n","\n","missing = []\n","for file in required_files:\n","    if os.path.exists(file):\n","        print(f\"✓ Found: {file}\")\n","    else:\n","        print(f\"✗ Missing: {file}\")\n","        missing.append(file)\n","\n","if missing:\n","    print(f\"\\n⚠ Warning: {len(missing)} required annotation file(s) are missing!\")\n","    print(\"Please ensure these files are available before running Step 3.\")\n","else:\n","    print(\"\\n✓ All required annotation files are present!\")\n"]},{"cell_type":"markdown","metadata":{"id":"qMZmSwCyUdbf"},"source":["## 3. Step 2: Feature Sanity Check\n","\n","This step verifies that your features are loaded correctly and can be read.\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"9rUsm7e0Udbf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808368371,"user_tz":-60,"elapsed":312,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"6a4072f4-4236-4691-80d8-0d50a4c66606"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Step 2: Feature Sanity Check\n","============================================================\n","\n","Features root: /content/aml_repo/aml_repo_v2/data\n","\n","--- Checking OMNIVORE ---\n","✓ Directory found: /content/aml_repo/aml_repo_v2/data/video/omnivore\n","  Found 384 .npz files\n","  Example files:\n","    - 10_16_360p.mp4_1s_1s.npz\n","    - 10_18_360p.mp4_1s_1s.npz\n","    - 10_24_360p.mp4_1s_1s.npz\n","    - 10_26_360p.mp4_1s_1s.npz\n","    - 10_31_360p.mp4_1s_1s.npz\n","\n","  Loading sample file: 10_16_360p.mp4_1s_1s.npz\n","  Keys in file: ['arr_0']\n","  Shape: (974, 1024)\n","  Dtype: float32\n","  Min: -3.1500, Max: 3.1098, Mean: -0.0166\n","\n","--- Checking SLOWFAST ---\n","✓ Directory found: /content/aml_repo/aml_repo_v2/data/video/slowfast\n","  Found 384 .npz files\n","  Example files:\n","    - 10_16_360p.mp4_1s_1s.npz\n","    - 10_18_360p.mp4_1s_1s.npz\n","    - 10_24_360p.mp4_1s_1s.npz\n","    - 10_26_360p.mp4_1s_1s.npz\n","    - 10_31_360p.mp4_1s_1s.npz\n","\n","  Loading sample file: 10_16_360p.mp4_1s_1s.npz\n","  Keys in file: ['arr_0']\n","  Shape: (974, 400)\n","  Dtype: float32\n","  Min: -9.9709, Max: 26.4474, Mean: -0.0000\n","\n","============================================================\n","Summary:\n","============================================================\n","✓ OMNIVORE: exists=True, files=384\n","    Sample shape: (974, 1024), dtype: float32\n","✓ SLOWFAST: exists=True, files=384\n","    Sample shape: (974, 400), dtype: float32\n"]}],"source":["# Run Step 2: Feature sanity check\n","!python scripts/run.py step2 --features_root data\n"]},{"cell_type":"markdown","metadata":{"id":"jnTpjYrYUdbf"},"source":["## 4. Step 3: Evaluation Reproduction\n","\n","Run evaluations to reproduce the results from the paper. Update checkpoint paths with actual epoch numbers from your checkpoints directory.\n","\n","**Note**: Use threshold 0.6 for `step` split and 0.4 for `recordings` split.\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"-nQKdPjmUdbf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808401354,"user_tz":-60,"elapsed":28540,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"c34b4110-54bc-467c-f66e-fd6622b1b2be"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Step 3: Evaluation Reproduction\n","============================================================\n","\n","Running: /usr/bin/python3 -m core.evaluate --split step --backbone omnivore --variant MLP --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt --threshold 0.6\n","\n","Loaded annotations...... \n","Loading recording ids from recordings_combined_splits.json\n","test Progress: 42347/798: 100% 798/798 [00:11<00:00, 71.64it/s]\n","----------------------------------------------------------------\n","test Sub Step Level Metrics: {'precision': 0.4096162736939436, 'recall': 0.2989708115404083, 'f1': 0.3456549302643129, 'accuracy': 0.6831416629277163, 'auc': np.float64(0.6541560352028618), 'pr_auc': tensor(0.3187)}\n","test Step Level Metrics: {'precision': 0.6607142857142857, 'recall': 0.14859437751004015, 'f1': 0.24262295081967214, 'accuracy': 0.7105263157894737, 'auc': np.float64(0.7573902166041213), 'pr_auc': tensor(0.3638)}\n","----------------------------------------------------------------\n"]}],"source":["# Example: Omnivore - MLP - Step split\n","# This should reproduce: F1=24.26, AUC=75.74\n","!python scripts/run.py step3 --split step --backbone omnivore --variant MLP \\\n","  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt \\\n","  --threshold 0.6\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kEmnB6HWUdbf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808703703,"user_tz":-60,"elapsed":11035,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"00df1199-ac78-46bc-ae66-8a988052e6e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Step 3: Evaluation Reproduction\n","============================================================\n","\n","Running: /usr/bin/python3 -m core.evaluate --split recordings --backbone omnivore --variant MLP --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_33.pt --threshold 0.4\n","\n","Loaded annotations...... \n","Loading recording ids from recordings_combined_splits.json\n","test Progress: 38340/671: 100% 671/671 [00:04<00:00, 148.32it/s]\n","----------------------------------------------------------------\n","test Sub Step Level Metrics: {'precision': 0.3964945261528254, 'recall': 0.5688109780280797, 'f1': 0.46727266803505685, 'accuracy': 0.5735263432446531, 'auc': np.float64(0.5988330748775713), 'pr_auc': tensor(0.3673)}\n","test Step Level Metrics: {'precision': 0.4090909090909091, 'recall': 0.8589211618257261, 'f1': 0.5542168674698795, 'accuracy': 0.503725782414307, 'auc': np.float64(0.6302808067162018), 'pr_auc': tensor(0.4020)}\n","----------------------------------------------------------------\n"]}],"source":["# Example: Omnivore - MLP - Recordings split\n","# This should reproduce: F1=55.42, AUC=63.03\n","# Update the epoch number in the checkpoint path\n","!python scripts/run.py step3 --split recordings --backbone omnivore --variant MLP \\\n","  --ckpt checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_33.pt \\\n","  --threshold 0.4\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"cKlkNzjXUdbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808739649,"user_tz":-60,"elapsed":12912,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"c33404bd-7661-4dae-dc50-0dcb59d35c58"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Step 3: Evaluation Reproduction\n","============================================================\n","\n","Running: /usr/bin/python3 -m core.evaluate --split step --backbone omnivore --variant Transformer --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_step_epoch_9.pt --threshold 0.6\n","\n","Loaded annotations...... \n","Loading recording ids from recordings_combined_splits.json\n","test Progress: 42347/798: 100% 798/798 [00:05<00:00, 137.96it/s]\n","----------------------------------------------------------------\n","test Sub Step Level Metrics: {'precision': 0.4445452483556362, 'recall': 0.6613801248523705, 'f1': 0.5317056629365887, 'accuracy': 0.6738848088412402, 'auc': np.float64(0.7461755308526944), 'pr_auc': tensor(0.3888)}\n","test Step Level Metrics: {'precision': 0.5155709342560554, 'recall': 0.5983935742971888, 'f1': 0.5539033457249071, 'accuracy': 0.6992481203007519, 'auc': np.float64(0.7561832027563805), 'pr_auc': tensor(0.4338)}\n","----------------------------------------------------------------\n"]}],"source":["# Example: Omnivore - Transformer - Step split\n","# This should reproduce: F1=55.39, AUC=75.62\n","# Update the epoch number in the checkpoint path\n","!python scripts/run.py step3 --split step --backbone omnivore --variant Transformer \\\n","  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_step_epoch_9.pt \\\n","  --threshold 0.6\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"6QVKa7uSUdbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808763186,"user_tz":-60,"elapsed":11598,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"9ff4b736-b372-4aec-9161-13a6c4a69231"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Step 3: Evaluation Reproduction\n","============================================================\n","\n","Running: /usr/bin/python3 -m core.evaluate --split recordings --backbone omnivore --variant Transformer --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_recordings_epoch_31.pt --threshold 0.4\n","\n","Loaded annotations...... \n","Loading recording ids from recordings_combined_splits.json\n","test Progress: 38340/671: 100% 671/671 [00:04<00:00, 138.06it/s]\n","----------------------------------------------------------------\n","test Sub Step Level Metrics: {'precision': 0.4491327720864185, 'recall': 0.35123344173871657, 'f1': 0.39419567346212053, 'accuracy': 0.645018257694314, 'auc': np.float64(0.6254427005929003), 'pr_auc': tensor(0.3711)}\n","test Step Level Metrics: {'precision': 0.45408163265306123, 'recall': 0.36929460580912865, 'f1': 0.4073226544622426, 'accuracy': 0.6140089418777943, 'auc': np.float64(0.6226768310334846), 'pr_auc': tensor(0.3942)}\n","----------------------------------------------------------------\n"]}],"source":["# Example: Omnivore - Transformer - Recordings split\n","# This should reproduce: F1=40.73, AUC=62.27\n","# Update the epoch number in the checkpoint path\n","!python scripts/run.py step3 --split recordings --backbone omnivore --variant Transformer \\\n","  --ckpt checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_recordings_epoch_31.pt \\\n","  --threshold 0.4\n"]},{"cell_type":"markdown","metadata":{"id":"IAEkeXGsUdbg"},"source":["## Additional Evaluations\n","\n","You can also run evaluations for SlowFast backbone or other configurations. Make sure to update the checkpoint paths with the correct epoch numbers from your checkpoints directory.\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"5PIwzH8kUdbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765808765164,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aexo Mir","userId":"17747197918940308979"}},"outputId":"11757c5b-3047-4e6d-9315-c89462c0f476"},"outputs":[{"output_type":"stream","name":"stdout","text":["Available checkpoints:\n","  checkpoints/error_recognition_best/MLP/3dresnet/error_recognition_MLP_3dresnet_environment_epoch_11.pt\n","  checkpoints/error_recognition_best/MLP/3dresnet/error_recognition_MLP_3dresnet_person_epoch_39.pt\n","  checkpoints/error_recognition_best/MLP/3dresnet/error_recognition_MLP_3dresnet_recordings_epoch_45.pt\n","  checkpoints/error_recognition_best/MLP/3dresnet/error_recognition_MLP_3dresnet_step_epoch_41.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_audio_environment_epoch_50.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_audio_person_epoch_8.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_audio_recordings_epoch_2.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_audio_step_epoch_28.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_audio_environment_epoch_31.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_audio_person_epoch_21.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_audio_recordings_epoch_41.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_audio_step_epoch_38.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_environment_epoch_11.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_person_epoch_48.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_recordings_epoch_42.pt\n","  checkpoints/error_recognition_best/MLP/imagebind/error_recognition_MLP_imagebind_video_step_epoch_37.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_environment_epoch_5.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_person_epoch_28.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_recordings_epoch_33.pt\n","  checkpoints/error_recognition_best/MLP/omnivore/error_recognition_MLP_omnivore_step_epoch_43.pt\n","  checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_environment_epoch_7.pt\n","  checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_person_epoch_3.pt\n","  checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_recordings_epoch_31.pt\n","  checkpoints/error_recognition_best/MLP/slowfast/error_recognition_MLP_slowfast_step_epoch_15.pt\n","  checkpoints/error_recognition_best/MLP/x3d/error_recognition_MLP_x3d_environment_epoch_2.pt\n","  checkpoints/error_recognition_best/MLP/x3d/error_recognition_MLP_x3d_person_epoch_13.pt\n","  checkpoints/error_recognition_best/MLP/x3d/error_recognition_MLP_x3d_recordings_epoch_5.pt\n","  checkpoints/error_recognition_best/MLP/x3d/error_recognition_MLP_x3d_step_epoch_15.pt\n","  checkpoints/error_recognition_best/Transformer/3dresnet/error_recognition_Transformer_3dresnet_environment_epoch_39.pt\n","  checkpoints/error_recognition_best/Transformer/3dresnet/error_recognition_Transformer_3dresnet_person_epoch_50.pt\n","  checkpoints/error_recognition_best/Transformer/3dresnet/error_recognition_Transformer_3dresnet_recordings_epoch_25.pt\n","  checkpoints/error_recognition_best/Transformer/3dresnet/error_recognition_Transformer_3dresnet_step_epoch_3.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_audio_environment_epoch_4.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_audio_person_epoch_19.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_audio_recordings_epoch_31.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_audio_step_epoch_44.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_audio_environment_epoch_8.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_audio_person_epoch_17.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_audio_recordings_epoch_5.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_audio_step_epoch_9.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_recordings_epoch_27.pt\n","  checkpoints/error_recognition_best/Transformer/imagebind/error_recognition_Transformer_imagebind_video_step_epoch_20.pt\n","  checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_environment_epoch_6.pt\n","  checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_person_epoch_4.pt\n","  checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_recordings_epoch_31.pt\n","  checkpoints/error_recognition_best/Transformer/omnivore/error_recognition_Transformer_omnivore_step_epoch_9.pt\n","  checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_environment_epoch_23.pt\n","  checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_person_epoch_20.pt\n","  checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_recordings_epoch_49.pt\n","  checkpoints/error_recognition_best/Transformer/slowfast/error_recognition_Transformer_slowfast_step_epoch_25.pt\n","  checkpoints/error_recognition_best/Transformer/x3d/error_recognition_Transformer_x3d_environment_epoch_49.pt\n","  checkpoints/error_recognition_best/Transformer/x3d/error_recognition_Transformer_x3d_person_epoch_6.pt\n","  checkpoints/error_recognition_best/Transformer/x3d/error_recognition_Transformer_x3d_recordings_epoch_43.pt\n","  checkpoints/error_recognition_best/Transformer/x3d/error_recognition_Transformer_x3d_step_epoch_40.pt\n"]}],"source":["# List available checkpoints to find correct epoch numbers\n","import os\n","import glob\n","\n","checkpoint_base = 'checkpoints/error_recognition_best'\n","if os.path.exists(checkpoint_base):\n","    print(\"Available checkpoints:\")\n","    for ckpt_file in sorted(glob.glob(os.path.join(checkpoint_base, '**/*.pt'), recursive=True)):\n","        print(f\"  {ckpt_file}\")\n","else:\n","    print(\"Checkpoints directory not found\")\n"]},{"cell_type":"markdown","metadata":{"id":"ieSc99u6Udbg"},"source":["## Troubleshooting\n","\n","### Common Issues:\n","\n","1. **Missing features**: Make sure you have uploaded both Omnivore and SlowFast features\n","2. **Missing checkpoints**: Download from the official Box link and extract properly\n","3. **Missing annotations**: Ensure annotation files are in the correct directories\n","4. **Wrong checkpoint path**: Use the cell above to list available checkpoints and update paths\n","5. **CUDA errors**: The code will automatically fall back to CPU if CUDA is not available\n","\n","### Getting Help:\n","- Check the README.md in the repository\n","- Verify all file paths are correct\n","- Ensure all dependencies are installed\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"https://github.com/aexomir/AML_mistake_detection/blob/feat/step02/notebooks/colab_reproduce_results.ipynb","timestamp":1765807349882}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}