{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training with EgoVLP Backbone\n",
        "\n",
        "Train MLP, Transformer, and RNN models with EgoVLP video backbone.\n",
        "\n",
        "## Workflow:\n",
        "1. Mount Google Drive\n",
        "2. Clone repository and install dependencies\n",
        "3. **Load annotations from Google Drive**\n",
        "4. Download pre-extracted EgoVLP features from HuggingFace\n",
        "5. Train models (MLP, Transformer, RNN) with EgoVLP backbone\n",
        "6. Evaluate and compare results\n",
        "\n",
        "## Prerequisites:\n",
        "- Set Colab secrets: `WANDB_API_KEY`, `HF_TOKEN`\n",
        "- EgoVLP features should be available on HuggingFace (run extract_new_backbones.ipynb first)\n",
        "- **Upload CaptainCook4D annotations to Google Drive** at `MyDrive/AML_mistake_detection/annotations/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "HF_DATASET_REPO = \"aexomir/captaincook4d-features\" \n",
        "REPO_URL = \"https://github.com/aexomir/AML_mistake_detection.git\"\n",
        "REPO_BRANCH = \"feat/extend-baseline\"\n",
        "\n",
        "# Google Drive path for annotations\n",
        "ANNOTATIONS_DRIVE_PATH = '/content/drive/MyDrive/AML_mistake_detection/annotations'\n",
        "\n",
        "# Backbone to train (EgoVLP only)\n",
        "BACKBONE = \"egovlp\"\n",
        "# Model variants\n",
        "VARIANTS = [\"MLP\", \"Transformer\", \"RNN\"]\n",
        "\n",
        "print(f\"Will train {len(VARIANTS)} variants with {BACKBONE} backbone\")\n",
        "print(f\"Backbone: {BACKBONE}\")\n",
        "print(f\"Variants: {VARIANTS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clone Repository and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$REPO_URL\" \"$REPO_BRANCH\"\n",
        "cd /content\n",
        "if [ ! -d \"AML_mistake_detection\" ]; then\n",
        "    git clone --branch \"$2\" \"$1\" AML_mistake_detection\n",
        "else\n",
        "    cd AML_mistake_detection && git pull\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/AML_mistake_detection')\n",
        "\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q wandb huggingface_hub\n",
        "\n",
        "print(\"✓ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Annotations from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Loading CaptainCook4D annotations...\")\n",
        "\n",
        "if os.path.exists(ANNOTATIONS_DRIVE_PATH):\n",
        "    print(f\"✓ Found annotations at: {ANNOTATIONS_DRIVE_PATH}\")\n",
        "    \n",
        "    # Copy annotation_json (step_annotations.json, error_annotations.json)\n",
        "    annotation_json_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'annotation_json')\n",
        "    if os.path.exists(annotation_json_src):\n",
        "        print(\"  Copying annotation_json files...\")\n",
        "        for file in os.listdir(annotation_json_src):\n",
        "            src = os.path.join(annotation_json_src, file)\n",
        "            dst = os.path.join('annotations/annotation_json', file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "                print(f\"    ✓ Copied {file}\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  annotation_json not found at {annotation_json_src}\")\n",
        "    \n",
        "    # Copy data_splits (optional)\n",
        "    data_splits_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'data_splits')\n",
        "    if os.path.exists(data_splits_src):\n",
        "        print(\"  Copying data_splits files...\")\n",
        "        for file in os.listdir(data_splits_src):\n",
        "            src = os.path.join(data_splits_src, file)\n",
        "            dst = os.path.join('annotations/data_splits', file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "                print(f\"    ✓ Copied {file}\")\n",
        "    \n",
        "    # Verify required files\n",
        "    required_files = [\n",
        "        'annotations/annotation_json/step_annotations.json',\n",
        "        'annotations/annotation_json/error_annotations.json',\n",
        "        'er_annotations/recordings_combined_splits.json'\n",
        "    ]\n",
        "    \n",
        "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "    \n",
        "    if missing_files:\n",
        "        print(f\"\\n❌ ERROR: Missing required annotation files:\")\n",
        "        for file in missing_files:\n",
        "            print(f\"  - {file}\")\n",
        "        print(\"\\nPlease ensure these files are in your Google Drive at:\")\n",
        "        print(f\"  {ANNOTATIONS_DRIVE_PATH}/\")\n",
        "        raise FileNotFoundError(\"Missing required annotation files\")\n",
        "    else:\n",
        "        print(\"\\n✅ All required annotation files loaded successfully!\")\n",
        "        \n",
        "else:\n",
        "    print(f\"❌ ERROR: Annotations directory not found at: {ANNOTATIONS_DRIVE_PATH}\")\n",
        "    print(\"\\nPlease upload CaptainCook4D annotations to Google Drive:\")\n",
        "    print(\"  Required structure:\")\n",
        "    print(\"  MyDrive/AML_mistake_detection/annotations/\")\n",
        "    print(\"    ├── annotation_json/\")\n",
        "    print(\"    │   ├── step_annotations.json\")\n",
        "    print(\"    │   └── error_annotations.json\")\n",
        "    print(\"    └── data_splits/ (optional)\")\n",
        "    print(\"\\nDownload from: https://captaincook4d.github.io/captain-cook/\")\n",
        "    raise FileNotFoundError(\"Annotations directory not found in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download EgoVLP Features from HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download, login, list_repo_files\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "\n",
        "# Login to HuggingFace\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(token=hf_token)\n",
        "\n",
        "# Create data/features directory structure\n",
        "features_base = Path('/content/AML_mistake_detection/data/features')\n",
        "backbone_dir = features_base / BACKBONE\n",
        "backbone_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Downloading {BACKBONE} features...\")\n",
        "\n",
        "# List all files in the EgoVLP directory on HF\n",
        "files = [f for f in list_repo_files(HF_DATASET_REPO, repo_type=\"dataset\") \n",
        "         if f.startswith(f\"{BACKBONE}/\") and f.endswith('.npy')]\n",
        "\n",
        "print(f\"Found {len(files)} feature files\")\n",
        "\n",
        "# Download each file\n",
        "for file_path in files:\n",
        "    filename = Path(file_path).name\n",
        "    local_path = backbone_dir / filename\n",
        "    \n",
        "    if not local_path.exists():\n",
        "        hf_hub_download(\n",
        "            repo_id=HF_DATASET_REPO,\n",
        "            repo_type=\"dataset\",\n",
        "            filename=file_path,\n",
        "            local_dir=features_base,\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "\n",
        "print(f\"✓ Downloaded {BACKBONE} features to {backbone_dir}\")\n",
        "print(f\"✓ Total files: {len(list(backbone_dir.glob('*.npy')))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup WandB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to WandB\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_key)\n",
        "\n",
        "print(\"✓ WandB configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Training configuration\n",
        "SPLIT = \"recordings\"\n",
        "THRESHOLD = 0.6\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "training_results = {}\n",
        "\n",
        "for variant in VARIANTS:\n",
        "    model_name = f\"{variant}_{BACKBONE}\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Select appropriate training script\n",
        "    if variant == \"RNN\":\n",
        "        train_script = \"scripts/train_rnn_baseline.py\"\n",
        "    else:\n",
        "        train_script = \"train_er.py\"\n",
        "    \n",
        "    # Build training command\n",
        "    cmd = [\n",
        "        sys.executable, train_script,\n",
        "        \"--backbone\", BACKBONE,\n",
        "        \"--variant\", variant,\n",
        "        \"--split\", SPLIT,\n",
        "        \"--threshold\", str(THRESHOLD),\n",
        "        \"--epochs\", str(EPOCHS),\n",
        "        \"--batch_size\", str(BATCH_SIZE),\n",
        "        \"--use_wandb\"\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        # Run training\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        training_results[model_name] = \"SUCCESS\"\n",
        "        print(f\"✓ {model_name} training completed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ {model_name} training failed:\")\n",
        "        print(e.stderr)\n",
        "        training_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in training_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluate Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "\n",
        "for variant in VARIANTS:\n",
        "    model_name = f\"{variant}_{BACKBONE}\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Build evaluation command\n",
        "    cmd = [\n",
        "        sys.executable, \"core/evaluate.py\",\n",
        "        \"--backbone\", BACKBONE,\n",
        "        \"--variant\", variant,\n",
        "        \"--split\", SPLIT,\n",
        "        \"--threshold\", str(THRESHOLD)\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        # Run evaluation\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        evaluation_results[model_name] = \"SUCCESS\"\n",
        "        print(f\"✓ {model_name} evaluation completed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"✗ {model_name} evaluation failed:\")\n",
        "        print(e.stderr)\n",
        "        evaluation_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Evaluation Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in evaluation_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Comparison Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract metrics from this notebook's outputs\n",
        "print(\"Extracting metrics...\")\n",
        "cmd = [sys.executable, \"analysis/extract_metrics.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate comparison tables\n",
        "print(\"\\nGenerating comparison tables...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_tables.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate visualizations\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_visualizations.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "print(\"\\n✓ All analysis complete!\")\n",
        "print(\"Check analysis/outputs/ for results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training with New Backbones: EgoVLP & PerceptionEncoder\n",
        "\n",
        "Train MLP, Transformer, and RNN models with new video backbones.\n",
        "\n",
        "## Workflow:\n",
        "1. Clone repository and install dependencies\n",
        "2. **Load annotations from Google Drive**\n",
        "3. Download pre-extracted features from HuggingFace\n",
        "4. Train models with EgoVLP and PerceptionEncoder backbones\n",
        "5. Evaluate and compare results\n",
        "\n",
        "## Prerequisites:\n",
        "- Set Colab secrets: `WANDB_API_KEY`, `HF_TOKEN`\n",
        "- Features should be available on HuggingFace (run extract_new_backbones.ipynb first)\n",
        "- **Upload CaptainCook4D annotations to Google Drive** at `MyDrive/AML_mistake_detection/annotations/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "HF_DATASET_REPO = \"aexomir/captaincook4d-features\" \n",
        "REPO_URL = \"https://github.com/aexomir/AML_mistake_detection.git\"\n",
        "REPO_BRANCH = \"feat/extend-baseline\"\n",
        "\n",
        "# Google Drive path for annotations\n",
        "ANNOTATIONS_DRIVE_PATH = '/content/drive/MyDrive/AML_mistake_detection/annotations'\n",
        "\n",
        "# Backbones to train\n",
        "BACKBONES = [\"egovlp\"]\n",
        "# Model variants\n",
        "VARIANTS = [\"MLP\", \"Transformer\", \"RNN\"]\n",
        "\n",
        "print(f\"Will train {len(BACKBONES)} backbones × {len(VARIANTS)} variants = {len(BACKBONES) * len(VARIANTS)} models\")\n",
        "print(f\"Backbones: {BACKBONES}\")\n",
        "print(f\"Variants: {VARIANTS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clone Repository and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$REPO_URL\" \"$REPO_BRANCH\"\n",
        "cd /content\n",
        "if [ ! -d \"AML_mistake_detection\" ]; then\n",
        "    git clone --branch \"$2\" \"$1\" AML_mistake_detection\n",
        "else\n",
        "    cd AML_mistake_detection && git pull\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/AML_mistake_detection')\n",
        "\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q wandb huggingface_hub\n",
        "\n",
        "print(\"✓ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Annotations from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Loading CaptainCook4D annotations...\")\n",
        "\n",
        "if os.path.exists(ANNOTATIONS_DRIVE_PATH):\n",
        "    print(f\"✓ Found annotations at: {ANNOTATIONS_DRIVE_PATH}\")\n",
        "    \n",
        "    # Copy annotation_json (step_annotations.json, error_annotations.json)\n",
        "    annotation_json_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'annotation_json')\n",
        "    if os.path.exists(annotation_json_src):\n",
        "        print(\"  Copying annotation_json files...\")\n",
        "        for file in os.listdir(annotation_json_src):\n",
        "            src = os.path.join(annotation_json_src, file)\n",
        "            dst = os.path.join('annotations/annotation_json', file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "                print(f\"    ✓ Copied {file}\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  annotation_json not found at {annotation_json_src}\")\n",
        "    \n",
        "    # Copy data_splits (optional)\n",
        "    data_splits_src = os.path.join(ANNOTATIONS_DRIVE_PATH, 'data_splits')\n",
        "    if os.path.exists(data_splits_src):\n",
        "        print(\"  Copying data_splits files...\")\n",
        "        for file in os.listdir(data_splits_src):\n",
        "            src = os.path.join(data_splits_src, file)\n",
        "            dst = os.path.join('annotations/data_splits', file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "                print(f\"    ✓ Copied {file}\")\n",
        "    \n",
        "    # Verify required files\n",
        "    required_files = [\n",
        "        'annotations/annotation_json/step_annotations.json',\n",
        "        'annotations/annotation_json/error_annotations.json',\n",
        "        'er_annotations/recordings_combined_splits.json'\n",
        "    ]\n",
        "    \n",
        "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "    \n",
        "    if missing_files:\n",
        "        print(f\"\\n❌ ERROR: Missing required annotation files:\")\n",
        "        for file in missing_files:\n",
        "            print(f\"  - {file}\")\n",
        "        print(\"\\nPlease ensure these files are in your Google Drive at:\")\n",
        "        print(f\"  {ANNOTATIONS_DRIVE_PATH}/\")\n",
        "        raise FileNotFoundError(\"Missing required annotation files\")\n",
        "    else:\n",
        "        print(\"\\n✅ All required annotation files loaded successfully!\")\n",
        "        \n",
        "else:\n",
        "    print(f\"❌ ERROR: Annotations directory not found at: {ANNOTATIONS_DRIVE_PATH}\")\n",
        "    print(\"\\nPlease upload CaptainCook4D annotations to Google Drive:\")\n",
        "    print(\"  Required structure:\")\n",
        "    print(\"  MyDrive/AML_mistake_detection/annotations/\")\n",
        "    print(\"    ├── annotation_json/\")\n",
        "    print(\"    │   ├── step_annotations.json\")\n",
        "    print(\"    │   └── error_annotations.json\")\n",
        "    print(\"    └── data_splits/ (optional)\")\n",
        "    print(\"\\nDownload from: https://captaincook4d.github.io/captain-cook/\")\n",
        "    raise FileNotFoundError(\"Annotations directory not found in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download Features from HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download, login, list_repo_files\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "\n",
        "# Login to HuggingFace\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(token=hf_token)\n",
        "\n",
        "# Create data/features directory structure\n",
        "features_base = Path('/content/AML_mistake_detection/data/features')\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    backbone_dir = features_base / backbone\n",
        "    backbone_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Downloading {backbone} features...\")\n",
        "    \n",
        "    # List all files in the backbone directory on HF\n",
        "    files = [f for f in list_repo_files(HF_DATASET_REPO, repo_type=\"dataset\") \n",
        "             if f.startswith(f\"{backbone}/\") and f.endswith('.npy')]\n",
        "    \n",
        "    print(f\"Found {len(files)} feature files\")\n",
        "    \n",
        "    # Download each file\n",
        "    for file_path in files:\n",
        "        filename = Path(file_path).name\n",
        "        local_path = backbone_dir / filename\n",
        "        \n",
        "        if not local_path.exists():\n",
        "            hf_hub_download(\n",
        "                repo_id=HF_DATASET_REPO,\n",
        "                repo_type=\"dataset\",\n",
        "                filename=file_path,\n",
        "                local_dir=features_base,\n",
        "                local_dir_use_symlinks=False\n",
        "            )\n",
        "    \n",
        "    print(f\"✓ Downloaded {backbone} features to {backbone_dir}\")\n",
        "\n",
        "print(\"\\n✓ All features downloaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup WandB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to WandB\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_key)\n",
        "\n",
        "print(\"✓ WandB configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Training configuration\n",
        "SPLIT = \"recordings\"\n",
        "THRESHOLD = 0.6\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "training_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Select appropriate training script\n",
        "        if variant == \"RNN\":\n",
        "            train_script = \"scripts/train_rnn_baseline.py\"\n",
        "        else:\n",
        "            train_script = \"train_er.py\"\n",
        "        \n",
        "        # Build training command\n",
        "        cmd = [\n",
        "            sys.executable, train_script,\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD),\n",
        "            \"--epochs\", str(EPOCHS),\n",
        "            \"--batch_size\", str(BATCH_SIZE),\n",
        "            \"--use_wandb\"\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run training\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            training_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} training completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} training failed:\")\n",
        "            print(e.stderr)\n",
        "            training_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in training_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluate Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Build evaluation command\n",
        "        cmd = [\n",
        "            sys.executable, \"core/evaluate.py\",\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD)\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run evaluation\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            evaluation_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} evaluation completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} evaluation failed:\")\n",
        "            print(e.stderr)\n",
        "            evaluation_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Evaluation Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in evaluation_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Comparison Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract metrics from this notebook's outputs\n",
        "print(\"Extracting metrics...\")\n",
        "cmd = [sys.executable, \"analysis/extract_metrics.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate comparison tables\n",
        "print(\"\\nGenerating comparison tables...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_tables.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate visualizations\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_visualizations.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "print(\"\\n✓ All analysis complete!\")\n",
        "print(\"Check analysis/outputs/ for results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training with New Backbones: EgoVLP & PerceptionEncoder\n",
        "\n",
        "Train MLP, Transformer, and RNN models with new video backbones.\n",
        "\n",
        "## Workflow:\n",
        "1. Clone repository and install dependencies\n",
        "2. Download pre-extracted features from HuggingFace\n",
        "3. Load annotations\n",
        "4. Train models with EgoVLP and PerceptionEncoder backbones\n",
        "5. Evaluate and compare results\n",
        "\n",
        "## Prerequisites:\n",
        "- Set Colab secrets: `WANDB_API_KEY`, `HF_TOKEN`\n",
        "- Features should be available on HuggingFace (run extract_new_backbones.ipynb first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "HF_DATASET_REPO = \"aexomir/captaincook4d-features\" \n",
        "REPO_URL = \"https://github.com/aexomir/AML_mistake_detection.git\"\n",
        "REPO_BRANCH = \"feat/extend-baseline\"\n",
        "\n",
        "# Backbones to train\n",
        "BACKBONES = [\"egovlp\", \"perceptionencoder\"]\n",
        "# Model variants\n",
        "VARIANTS = [\"MLP\", \"Transformer\", \"RNN\"]\n",
        "\n",
        "print(f\"Will train {len(BACKBONES)} backbones × {len(VARIANTS)} variants = {len(BACKBONES) * len(VARIANTS)} models\")\n",
        "print(f\"Backbones: {BACKBONES}\")\n",
        "print(f\"Variants: {VARIANTS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Repository and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$REPO_URL\" \"$REPO_BRANCH\"\n",
        "cd /content\n",
        "if [ ! -d \"AML_mistake_detection\" ]; then\n",
        "    git clone --branch \"$2\" \"$1\" AML_mistake_detection\n",
        "else\n",
        "    cd AML_mistake_detection && git pull\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/AML_mistake_detection')\n",
        "\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q wandb huggingface_hub\n",
        "\n",
        "print(\"✓ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Features from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download, login, list_repo_files\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "\n",
        "# Login to HuggingFace\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(token=hf_token)\n",
        "\n",
        "# Create data/features directory structure\n",
        "features_base = Path('/content/AML_mistake_detection/data/features')\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    backbone_dir = features_base / backbone\n",
        "    backbone_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Downloading {backbone} features...\")\n",
        "    \n",
        "    # List all files in the backbone directory on HF\n",
        "    files = [f for f in list_repo_files(HF_DATASET_REPO, repo_type=\"dataset\") \n",
        "             if f.startswith(f\"{backbone}/\") and f.endswith('.npy')]\n",
        "    \n",
        "    print(f\"Found {len(files)} feature files\")\n",
        "    \n",
        "    # Download each file\n",
        "    for file_path in files:\n",
        "        filename = Path(file_path).name\n",
        "        local_path = backbone_dir / filename\n",
        "        \n",
        "        if not local_path.exists():\n",
        "            hf_hub_download(\n",
        "                repo_id=HF_DATASET_REPO,\n",
        "                repo_type=\"dataset\",\n",
        "                filename=file_path,\n",
        "                local_dir=features_base,\n",
        "                local_dir_use_symlinks=False\n",
        "            )\n",
        "    \n",
        "    print(f\"✓ Downloaded {backbone} features to {backbone_dir}\")\n",
        "\n",
        "print(\"\\n✓ All features downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to WandB\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_key)\n",
        "\n",
        "print(\"✓ WandB configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Training configuration\n",
        "SPLIT = \"recordings\"\n",
        "THRESHOLD = 0.6\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "training_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Select appropriate training script\n",
        "        if variant == \"RNN\":\n",
        "            train_script = \"scripts/train_rnn_baseline.py\"\n",
        "        else:\n",
        "            train_script = \"train_er.py\"\n",
        "        \n",
        "        # Build training command\n",
        "        cmd = [\n",
        "            sys.executable, train_script,\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD),\n",
        "            \"--epochs\", str(EPOCHS),\n",
        "            \"--batch_size\", str(BATCH_SIZE),\n",
        "            \"--use_wandb\"\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run training\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            training_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} training completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} training failed:\")\n",
        "            print(e.stderr)\n",
        "            training_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in training_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Build evaluation command\n",
        "        cmd = [\n",
        "            sys.executable, \"core/evaluate.py\",\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD)\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run evaluation\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            evaluation_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} evaluation completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} evaluation failed:\")\n",
        "            print(e.stderr)\n",
        "            evaluation_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Evaluation Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in evaluation_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Comparison Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract metrics from this notebook's outputs\n",
        "print(\"Extracting metrics...\")\n",
        "cmd = [sys.executable, \"analysis/extract_metrics.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate comparison tables\n",
        "print(\"\\nGenerating comparison tables...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_tables.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate visualizations\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_visualizations.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "print(\"\\n✓ All analysis complete!\")\n",
        "print(\"Check analysis/outputs/ for results\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
