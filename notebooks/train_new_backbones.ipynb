{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - Update these values!\n",
        "HF_DATASET_REPO = \"your-username/captaincook4d-features\"  # UPDATE THIS!\n",
        "REPO_URL = \"https://github.com/your-username/AML_mistake_detection.git\"  # UPDATE THIS!\n",
        "REPO_BRANCH = \"main\"  # or your branch name\n",
        "\n",
        "# Backbones to train\n",
        "BACKBONES = [\"egovlp\", \"perceptionencoder\"]\n",
        "# Model variants\n",
        "VARIANTS = [\"MLP\", \"Transformer\", \"RNN\"]\n",
        "\n",
        "print(f\"Will train {len(BACKBONES)} backbones × {len(VARIANTS)} variants = {len(BACKBONES) * len(VARIANTS)} models\")\n",
        "print(f\"Backbones: {BACKBONES}\")\n",
        "print(f\"Variants: {VARIANTS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Repository and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$REPO_URL\" \"$REPO_BRANCH\"\n",
        "cd /content\n",
        "if [ ! -d \"AML_mistake_detection\" ]; then\n",
        "    git clone --branch \"$2\" \"$1\" AML_mistake_detection\n",
        "else\n",
        "    cd AML_mistake_detection && git pull\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/AML_mistake_detection')\n",
        "\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q wandb huggingface_hub\n",
        "\n",
        "print(\"✓ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Features from HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download, login, list_repo_files\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "\n",
        "# Login to HuggingFace\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(token=hf_token)\n",
        "\n",
        "# Create data/features directory structure\n",
        "features_base = Path('/content/AML_mistake_detection/data/features')\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    backbone_dir = features_base / backbone\n",
        "    backbone_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Downloading {backbone} features...\")\n",
        "    \n",
        "    # List all files in the backbone directory on HF\n",
        "    files = [f for f in list_repo_files(HF_DATASET_REPO, repo_type=\"dataset\") \n",
        "             if f.startswith(f\"{backbone}/\") and f.endswith('.npy')]\n",
        "    \n",
        "    print(f\"Found {len(files)} feature files\")\n",
        "    \n",
        "    # Download each file\n",
        "    for file_path in files:\n",
        "        filename = Path(file_path).name\n",
        "        local_path = backbone_dir / filename\n",
        "        \n",
        "        if not local_path.exists():\n",
        "            hf_hub_download(\n",
        "                repo_id=HF_DATASET_REPO,\n",
        "                repo_type=\"dataset\",\n",
        "                filename=file_path,\n",
        "                local_dir=features_base,\n",
        "                local_dir_use_symlinks=False\n",
        "            )\n",
        "    \n",
        "    print(f\"✓ Downloaded {backbone} features to {backbone_dir}\")\n",
        "\n",
        "print(\"\\n✓ All features downloaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup WandB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to WandB\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_key)\n",
        "\n",
        "print(\"✓ WandB configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Training configuration\n",
        "SPLIT = \"recordings\"\n",
        "THRESHOLD = 0.6\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "training_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Select appropriate training script\n",
        "        if variant == \"RNN\":\n",
        "            train_script = \"scripts/train_rnn_baseline.py\"\n",
        "        else:\n",
        "            train_script = \"train_er.py\"\n",
        "        \n",
        "        # Build training command\n",
        "        cmd = [\n",
        "            sys.executable, train_script,\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD),\n",
        "            \"--epochs\", str(EPOCHS),\n",
        "            \"--batch_size\", str(BATCH_SIZE),\n",
        "            \"--use_wandb\"\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run training\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            training_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} training completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} training failed:\")\n",
        "            print(e.stderr)\n",
        "            training_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in training_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "\n",
        "for backbone in BACKBONES:\n",
        "    for variant in VARIANTS:\n",
        "        model_name = f\"{variant}_{backbone}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Build evaluation command\n",
        "        cmd = [\n",
        "            sys.executable, \"core/evaluate.py\",\n",
        "            \"--backbone\", backbone,\n",
        "            \"--variant\", variant,\n",
        "            \"--split\", SPLIT,\n",
        "            \"--threshold\", str(THRESHOLD)\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run evaluation\n",
        "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(result.stdout)\n",
        "            evaluation_results[model_name] = \"SUCCESS\"\n",
        "            print(f\"✓ {model_name} evaluation completed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {model_name} evaluation failed:\")\n",
        "            print(e.stderr)\n",
        "            evaluation_results[model_name] = \"FAILED\"\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Evaluation Summary:\")\n",
        "print(f\"{'='*60}\")\n",
        "for model, status in evaluation_results.items():\n",
        "    status_icon = \"✓\" if status == \"SUCCESS\" else \"✗\"\n",
        "    print(f\"{status_icon} {model}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Comparison Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract metrics from this notebook's outputs\n",
        "print(\"Extracting metrics...\")\n",
        "cmd = [sys.executable, \"analysis/extract_metrics.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate comparison tables\n",
        "print(\"\\nGenerating comparison tables...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_tables.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "# Generate visualizations\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "cmd = [sys.executable, \"analysis/comparison_visualizations.py\"]\n",
        "subprocess.run(cmd, check=True)\n",
        "\n",
        "print(\"\\n✓ All analysis complete!\")\n",
        "print(\"Check analysis/outputs/ for results\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
